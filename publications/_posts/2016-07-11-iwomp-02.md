---
layout: publication
title: "The Secrets of the Accelerators Unveiled: Tracing Heterogeneous Executions Through OMPT"
short: "IWOMP 2016 (2)"
people: " Germán Llort, Antonio Filgueras, Daniel Jiménez-González, Harald Servat, Xavier Teruel, Estanislao Mercadal, Carlos Álvarez, Judit Giménez, Xavier Martorell, Eduard Ayguadé and Jesús Labarta "
info: "In Proceedings of IWOMP 2016. 12th International Workshop on OpenMP. (p. 217-236)"
venue: "Nara, JAPAN"
event: 2016-10-05
tags: [IWOMP, OpenMP, Instrumentation, OMPT]
comments: true
---

Extending previous efforts in the field to expose detailed information from the
OpenMP and OmpSs runtimes, regarding the activity and performance of task-based
parallel applications.


### Abstract
Heterogeneous systems are an important trend in the future of supercomputers,
yet they can be hard to program and developers still lack powerful tools to
gain understanding about how well their accelerated codes perform and how to
improve them.

Having different types of hardware accelerators available, each with their own
specific low-level APIs to program them, there is not yet a clear consensus on
a standard way to retrieve information about the accelerator’s performance. To
improve this scenario, OMPT is a novel performance monitoring interface that is
being considered for integration into the OpenMP standard. OMPT allows analysis
tools to monitor the execution of parallel OpenMP applications by providing
detailed information about the activity of the runtime through a standard API.
For accelerated devices, OMPT also facilitates the exchange of performance
information between the runtime and the analysis tool. We implement part of the
OMPT specification that refers to the use of accelerators both in the Nanos++
parallel runtime system and the Extrae tracing framework, obtaining detailed
performance information about the execution of the tasks issued to the
accelerated devices to later conduct insightful analysis.

Our work extends previous efforts in the field to expose detailed information
from the OpenMP and OmpSs runtimes, regarding the activity and performance of
task-based parallel applications. In this paper, we focus on the evaluation of
FPGA devices studying the performance of two common kernels in scientific
algorithms: matrix multiplication and Cholesky decomposition. Furthermore, this
development is seamlessly applicable for the analysis of GPGPU accelerators and
Intel Xeon Phi co-processors operating under the OmpSs programming model.
